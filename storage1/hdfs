[hdfs@node01 ~]$ cd /opt/cloudera/parcels/CDH-5.7.0-1.cdh5.7.0.p0.45/lib/hadoop-0.20-mapreduce/
[hdfs@node01 hadoop-0.20-mapreduce]$ hadoop jar hadoop-examples.jar  teragen 10000000 terasort/1G-input
16/05/18 12:04:11 INFO client.RMProxy: Connecting to ResourceManager at node01/192.168.60.71:8032
16/05/18 12:04:12 INFO terasort.TeraSort: Generating 10000000 using 2
16/05/18 12:04:12 INFO mapreduce.JobSubmitter: number of splits:2
16/05/18 12:04:12 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1463533040225_0001
16/05/18 12:04:13 INFO impl.YarnClientImpl: Submitted application application_1463533040225_0001
16/05/18 12:04:13 INFO mapreduce.Job: The url to track the job: http://node01:8088/proxy/application_1463533040225_0001/
16/05/18 12:04:13 INFO mapreduce.Job: Running job: job_1463533040225_0001
16/05/18 12:04:21 INFO mapreduce.Job: Job job_1463533040225_0001 running in uber mode : false
16/05/18 12:04:21 INFO mapreduce.Job:  map 0% reduce 0%
16/05/18 12:04:34 INFO mapreduce.Job:  map 65% reduce 0%
16/05/18 12:04:36 INFO mapreduce.Job:  map 80% reduce 0%
16/05/18 12:04:37 INFO mapreduce.Job:  map 100% reduce 0%
16/05/18 12:04:37 INFO mapreduce.Job: Job job_1463533040225_0001 completed successfully
16/05/18 12:04:38 INFO mapreduce.Job: Counters: 31
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=233576
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=167
		HDFS: Number of bytes written=1000000000
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Job Counters 
		Launched map tasks=2
		Other local map tasks=2
		Total time spent by all maps in occupied slots (ms)=26573
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=26573
		Total vcore-seconds taken by all map tasks=26573
		Total megabyte-seconds taken by all map tasks=27210752
	Map-Reduce Framework
		Map input records=10000000
		Map output records=10000000
		Input split bytes=167
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=226
		CPU time spent (ms)=26420
		Physical memory (bytes) snapshot=747204608
		Virtual memory (bytes) snapshot=3098927104
		Total committed heap usage (bytes)=657457152
	org.apache.hadoop.examples.terasort.TeraGen$Counters
		CHECKSUM=21472776955442690
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=1000000000
[hdfs@node01 hadoop-0.20-mapreduce]$ 


hadoop jar hadoop-examples.jar  teragen 10000000 terasort/1G-input


[hdfs@node01 hadoop-0.20-mapreduce]$ hadoop fs -ls
Found 2 items
drwx------   - hdfs supergroup          0 2016-05-18 12:04 .staging
drwxr-xr-x   - hdfs supergroup          0 2016-05-18 12:04 terasort

[hdfs@node01 hadoop-0.20-mapreduce]$ hadoop fs -ls terasort/1G-input
Found 3 items
-rw-r--r--   3 hdfs supergroup          0 2016-05-18 12:04 terasort/1G-input/_SUCCESS
-rw-r--r--   3 hdfs supergroup  500000000 2016-05-18 12:04 terasort/1G-input/part-m-00000
-rw-r--r--   3 hdfs supergroup  500000000 2016-05-18 12:04 terasort/1G-input/part-m-00001
[hdfs@node01 hadoop-0.20-mapreduce]$ 


[hdfs@node01 hadoop-0.20-mapreduce]$ hadoop jar hadoop-examples.jar terasort terasort/1G-input terasort/1G-output
16/05/18 12:13:07 INFO terasort.TeraSort: starting
16/05/18 12:13:09 INFO input.FileInputFormat: Total input paths to process : 2
Spent 192ms computing base-splits.
Spent 4ms computing TeraScheduler splits.
Computing input splits took 197ms
Sampling 8 splits of 8
Making 8 from 100000 sampled records
Computing parititions took 815ms
Spent 1015ms computing partitions.
16/05/18 12:13:10 INFO client.RMProxy: Connecting to ResourceManager at node01/192.168.60.71:8032
16/05/18 12:13:10 INFO mapreduce.JobSubmitter: number of splits:8
16/05/18 12:13:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1463533040225_0002
16/05/18 12:13:11 INFO impl.YarnClientImpl: Submitted application application_1463533040225_0002
16/05/18 12:13:11 INFO mapreduce.Job: The url to track the job: http://node01:8088/proxy/application_1463533040225_0002/
16/05/18 12:13:11 INFO mapreduce.Job: Running job: job_1463533040225_0002
16/05/18 12:13:18 INFO mapreduce.Job: Job job_1463533040225_0002 running in uber mode : false
16/05/18 12:13:18 INFO mapreduce.Job:  map 0% reduce 0%
16/05/18 12:13:28 INFO mapreduce.Job:  map 13% reduce 0%
16/05/18 12:13:29 INFO mapreduce.Job:  map 25% reduce 0%
16/05/18 12:13:31 INFO mapreduce.Job:  map 38% reduce 0%
16/05/18 12:13:38 INFO mapreduce.Job:  map 50% reduce 0%
16/05/18 12:13:40 INFO mapreduce.Job:  map 63% reduce 0%
16/05/18 12:13:42 INFO mapreduce.Job:  map 75% reduce 0%
16/05/18 12:13:48 INFO mapreduce.Job:  map 88% reduce 0%
16/05/18 12:13:50 INFO mapreduce.Job:  map 100% reduce 0%
16/05/18 12:14:00 INFO mapreduce.Job:  map 100% reduce 25%
16/05/18 12:14:01 INFO mapreduce.Job:  map 100% reduce 38%
16/05/18 12:14:10 INFO mapreduce.Job:  map 100% reduce 50%
16/05/18 12:14:11 INFO mapreduce.Job:  map 100% reduce 75%
16/05/18 12:14:18 INFO mapreduce.Job:  map 100% reduce 88%
16/05/18 12:14:19 INFO mapreduce.Job:  map 100% reduce 100%
16/05/18 12:14:20 INFO mapreduce.Job: Job job_1463533040225_0002 completed successfully
16/05/18 12:14:20 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=443030807
		FILE: Number of bytes written=885066919
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1000000992
		HDFS: Number of bytes written=1000000000
		HDFS: Number of read operations=48
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=16
	Job Counters 
		Launched map tasks=8
		Launched reduce tasks=8
		Data-local map tasks=6
		Rack-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=74648
		Total time spent by all reduces in occupied slots (ms)=66257
		Total time spent by all map tasks (ms)=74648
		Total time spent by all reduce tasks (ms)=66257
		Total vcore-seconds taken by all map tasks=74648
		Total vcore-seconds taken by all reduce tasks=66257
		Total megabyte-seconds taken by all map tasks=76439552
		Total megabyte-seconds taken by all reduce tasks=67847168
	Map-Reduce Framework
		Map input records=10000000
		Map output records=10000000
		Map output bytes=1020000000
		Map output materialized bytes=440145104
		Input split bytes=992
		Combine input records=0
		Combine output records=0
		Reduce input groups=10000000
		Reduce shuffle bytes=440145104
		Reduce input records=10000000
		Reduce output records=10000000
		Spilled Records=20000000
		Shuffled Maps =64
		Failed Shuffles=0
		Merged Map outputs=64
		GC time elapsed (ms)=2877
		CPU time spent (ms)=120350
		Physical memory (bytes) snapshot=7912808448
		Virtual memory (bytes) snapshot=25229557760
		Total committed heap usage (bytes)=8276934656
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1000000000
	File Output Format Counters 
		Bytes Written=1000000000
16/05/18 12:14:20 INFO terasort.TeraSort: done
[hdfs@node01 hadoop-0.20-mapreduce]$ 


[hdfs@node01 hadoop-0.20-mapreduce]$ hadoop fs -ls terasort/1G-output
Found 10 items
-rw-r--r--   1 hdfs supergroup          0 2016-05-18 12:14 terasort/1G-output/_SUCCESS
-rw-r--r--  10 hdfs supergroup         77 2016-05-18 12:13 terasort/1G-output/_partition.lst
-rw-r--r--   1 hdfs supergroup  125089700 2016-05-18 12:13 terasort/1G-output/part-r-00000
-rw-r--r--   1 hdfs supergroup  125211600 2016-05-18 12:13 terasort/1G-output/part-r-00001
-rw-r--r--   1 hdfs supergroup  125512700 2016-05-18 12:14 terasort/1G-output/part-r-00002
-rw-r--r--   1 hdfs supergroup  124501500 2016-05-18 12:14 terasort/1G-output/part-r-00003
-rw-r--r--   1 hdfs supergroup  122787100 2016-05-18 12:14 terasort/1G-output/part-r-00004
-rw-r--r--   1 hdfs supergroup  126215600 2016-05-18 12:14 terasort/1G-output/part-r-00005
-rw-r--r--   1 hdfs supergroup  125842200 2016-05-18 12:14 terasort/1G-output/part-r-00006
-rw-r--r--   1 hdfs supergroup  124839600 2016-05-18 12:14 terasort/1G-output/part-r-00007
[hdfs@node01 hadoop-0.20-mapreduce]$ 
